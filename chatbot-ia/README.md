# Chatbot IA com TypeScript

Este projeto implementa um chatbot simples utilizando TypeScript com suporte para mÃºltiplos provedores de IA:

- **Gemini:** IntegraÃ§Ã£o com a API do Google Generative Language.
- **Groq:** IntegraÃ§Ã£o com o SDK do Groq para respostas em streaming.
- **Ollama:** IntegraÃ§Ã£o com o SDK do Ollama para gerar respostas de chat.

## ğŸš€ Recursos

- **Seletor de IA:** Escolha o provedor de IA a ser utilizado via interface de linha de comando.
- **IntegraÃ§Ã£o com mÃºltiplos provedores:** ImplementaÃ§Ãµes especÃ­ficas para Gemini, Groq e Ollama.
- **Streaming de respostas:** Suporte para streaming de respostas (Groq e, opcionalmente, Ollama).

## ğŸ“‚ Estrutura do Projeto

```plaintext
chatbot-ia/
â”‚â”€â”€ .env                  # VariÃ¡veis de ambiente (API keys, host, etc.)
â”‚â”€â”€ .gitignore            # Arquivos e pastas ignorados pelo Git (node_modules, dist, .env, etc.)
â”‚â”€â”€ package.json          # ConfiguraÃ§Ãµes e dependÃªncias do NPM
â”‚â”€â”€ tsconfig.json         # ConfiguraÃ§Ãµes do TypeScript
â”‚â”€â”€ README.md             # Este arquivo
â”‚
â””â”€â”€ src/                  # CÃ³digo-fonte do projeto
    â”‚â”€â”€ index.ts          # Arquivo principal que inicia o chatbot e exibe o menu
    â”‚â”€â”€ IAProvider.ts     # Interface comum para os provedores de IA
    â”‚â”€â”€ geminiProvider.ts # ImplementaÃ§Ã£o do provedor Gemini
    â”‚â”€â”€ groqProvider.ts   # ImplementaÃ§Ã£o do provedor Groq
    â””â”€â”€ ollamaProvider.ts # ImplementaÃ§Ã£o do provedor Ollama

## ğŸ› ï¸ PrÃ©-requisitos

Antes de rodar o projeto, certifique-se de ter:

- [Node.js](https://nodejs.org/) (v14 ou superior)
- NPM (geralmente instalado com o Node.js)
- **Para o Ollama:**  
  Certifique-se de que o servidor Ollama esteja instalado e em execuÃ§Ã£o.  
  O servidor padrÃ£o roda em: `http://127.0.0.1:11434`.

## ğŸ“¥ InstalaÃ§Ã£o

### 1ï¸âƒ£ Clone o repositÃ³rio:

```bash
git clone <URL_DO_REPOSITORIO>
cd chatbot-ia
2ï¸âƒ£ Instale as dependÃªncias:
npm install
3ï¸âƒ£ Configure as variÃ¡veis de ambiente:
Crie um arquivo .env na raiz do projeto com o seguinte conteÃºdo:

# Gemini: API Key obtida na plataforma do Google
GEMINI_API_KEY=your_gemini_api_key_here

# Groq: API Key obtida na plataforma do Groq
GROQ_API_KEY=your_groq_api_key_here

# Ollama: EndereÃ§o do servidor Ollama (padrÃ£o: http://127.0.0.1:11434)
OLLAMA_HOST=http://127.0.0.1:11434
â–¶ï¸ Executando o Projeto

Para rodar o chatbot, execute:

npx ts-node src/index.ts
ApÃ³s iniciar, vocÃª verÃ¡ um menu como este:

Selecione a IA desejada:
1 - Gemini
2 - Ollama
3 - Eliza
4 - Groq
OpÃ§Ã£o:
Escolha um nÃºmero e pressione Enter para testar o chatbot.

ğŸ” Detalhes dos Provedores

ğŸ”¹ Gemini
DescriÃ§Ã£o: API do Google Generative Language.
Endpoint:
https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=<GEMINI_API_KEY>
ConfiguraÃ§Ã£o:
Defina a chave de API no .env como GEMINI_API_KEY.
ğŸ”¹ Groq
DescriÃ§Ã£o: API do Groq para geraÃ§Ã£o de respostas em streaming.
Endpoint:
https://api.groq.com/openai/v1/chat/completions
ConfiguraÃ§Ã£o:
Defina a chave de API no .env como GROQ_API_KEY.
ğŸ”¹ Ollama
DescriÃ§Ã£o: Utiliza o SDK do Ollama para chat.
Modelo PadrÃ£o: llama3.1
Se o modelo nÃ£o for encontrado:
Execute ollama pull llama3.1 para baixar o modelo.
Ou altere o nome do modelo em src/ollamaProvider.ts.
ConfiguraÃ§Ã£o:
O host Ã© configurado via OLLAMA_HOST no .env.
âš ï¸ Problemas Comuns e SoluÃ§Ãµes

âŒ Erro: model 'llama3.1' not found
SoluÃ§Ã£o: Execute o comando abaixo para baixar o modelo:

ollama pull llama3.1
Ou altere o nome do modelo em src/ollamaProvider.ts.

âŒ Erro: ECONNREFUSED (ConexÃ£o recusada)
SoluÃ§Ã£o:

Verifique se o servidor Ollama estÃ¡ rodando (http://127.0.0.1:11434).
Confirme a variÃ¡vel OLLAMA_HOST no .env.
ğŸ”§ Comandos Ãšteis

Instalar dependÃªncias:
npm install
Executar o projeto:
npx ts-node src/index.ts
ğŸ“œ LicenÃ§a

Este projeto estÃ¡ licenciado sob a MIT License.

ğŸ™Œ Agradecimentos

Projeto desenvolvido como parte do desafio "IA com TypeScript".

A equipe **MultiversX Dojo** Ã© composta pelos seguintes membros:

| Nome | GitHub |
|------|--------|
| Uederson Ferreira | [@uederson-ferreira](https://github.com/uederson-ferreira) |
| Luciano Zanin | [@usuario2](https://github.com/usuario2) |
| Kelvin Tanita | [@usuario3](https://github.com/usuario3) |
